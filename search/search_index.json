{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Welcome to AImon5.0","text":""},{"location":"index.html#main-3dgeo-outcomes-of-the-aimon50-project","title":"Main 3DGeo outcomes of the AImon5.0 project","text":"<ul> <li>New open-source software Voxel Analysis for Point Clouds</li> <li>Contributions and improvements to the open-source software py4dgeo</li> <li>Proof-of-concept workflow implementation and representative examples of potential use cases. Our list of examples is a perfect start to learn how to use our source codes in your own projects</li> <li>Scientific publications and talks at conferences</li> </ul>"},{"location":"index.html#research-project-at-a-glance","title":"\ud83d\udcd1 Research project at a glance","text":"Modern permanently installed laser scanners can deliver sub\u2010hourly point clouds, opening the door to early warning of surface deformations. Current workflows struggle to keep pace with such data volumes in near real-time. Vegetation and occlusions in forested or complex terrain further degrade ground\u2010point coverage, undermining the reliability of change estimates. As a result, there remains a critical need for efficient, robust processing strategies that can detect and quantify subtle surface shifts.  The project AImon5.0 was funded by the Federal Ministry of Research, Technology and Space (BMBF) within the funding measure \"Digital GreenTech \u2013 Environmental Engineering meets Digitalisation\" as part of the \"Research for Sustainability (FONA) Strategy\". Please find more project details on our website."},{"location":"index.html#overall-objective","title":"Overall objective","text":"Our environment and the Earth's surface are constantly changing, and global warming and climate change are accelerating the pace and magnitude of these changes. As a result, geohazards, triggered by natural events or human activities, are becoming more frequent. For example, intense and prolonged rainfall or thawing of permafrost in the Alps are increasingly causing landslides and rockfalls that threaten local populations and critical infrastructure such as railways and roads, with serious economic consequences.  A key tool for integrated risk management is access to relevant 4D geospatial information (accurate 3D data with high temporal resolution) acquired through near real-time, permanent or on-demand monitoring. Permanently installed autonomous laser scanning (PLS) systems have shown great potential for monitoring hazard zones, producing billions of 3D measurements daily. Computational methods to analyze this data exist, but to make it operational, a new interface is needed to bridge application needs with 4D data collection and analysis.  This interface connects stakeholder expertise with autonomous PLS systems and data archives using AI and 4D analysis. It enables the operational use of PLS for risk monitoring - detecting and tracking relevant events such as slope activity in real time. For the first time, stakeholders are able to use PLS for continuous hazard monitoring."},{"location":"index.html#study-site","title":"Study site","text":"The goal of this project was to bridge the gap between research and practice. While key methods for multi-temporal analysis and subtopics such as uncertainty in change detection had been previously developed, this project focused on refining and extending them for practical, application-oriented use. The  3DGeo Research Group Heidelberg developed computer-based methods for automatic information extraction and visualization from 4D-PLS data as their main focus in the AImon5.0 project. The study site was located in Trier, Germany (Fig. 1), at the Trierer Augenscheiner (Fig. 2).         Study site of the AImon5.0 project located in Trier in Germany (red dot)."},{"location":"index.html#method-development-and-implementation","title":"Method development and implementation","text":"The developed methods are particularly suitable for operational use and adapted in order to deliver reliable and timely results. Automated information extraction represents a central interface between the PLS system in the field, the quality-assured change information, and the end users. Scientifically, we investigated and combined two complementary concepts that can integrate expert knowledge into automated data analysis:  \u00a0\u00a0\u00a0\u00a0 1. Top-down approach via a knowledge- and rule-based classification of changes: In that case, the users know exactly which events they want to find in the data streams and how these processes (e.g., abrupt rockfall) are defined in their sequence. A set of new methods and tools for data management for fast and accurate searches were developed and evaluated; \u00a0\u00a0\u00a0\u00a0 2. Data-driven approach using AI: Machine learning methods find relevant change events after a user-controlled training phase and present them to the experts for evaluation. The users do not know in advance how the events, possibly also overlaid processes, are represented in the raw data. However, the users can distinguish relevant from non-relevant extracted events for their use case and thus train an AI model.  For the second approach, research was carried out to find out how the state-of-the-art point cloud-based machine learning models can be trained quickly and as automatically as possible in the background and how their hyperparameters can be optimized. In coordination with end users and the PLS operator, it was determined which abstraction levels and visualization forms are best suited for certain tasks, as well as specified reaction times, for the visualization of the detected and classified changes. In contrast to visualization in 2D and 3D (e.g., in GIS or dashboards), fundamental research was carried out for the visualization of 4D processes in PLS data due to a lack of existing methods and tools."},{"location":"index.html#work-packages","title":"\u2699\ufe0f Work packages","text":"The following methods were developed by the  3DGeo Research Group within their main work packages."},{"location":"index.html#new-concept-of-change-events","title":"New concept of 'change events'","text":"A change event is characterized by different attributes, each representing a measurable dimension of the change. The diagram of Fig. 3 highlights the modular structure of change events, emphasizing how temporal and spatial metrics combine to define and categorize observed changes. A classifier assigns an event type to the change based on the characteristics, enabling semantic interpretation of what kind of event occurred (e.g., gravitational mass movement, change in vegetation, etc). <p>Research target 1 - Hierarchical classification of detected change: </p> Developing new methods and tools to automatically extract relevant change information from the last two point clouds. The method analyses different types of change in the terrain (e.g., rockfall events, movements or erosion processes) fully automatically by delimiting them in terms of time and space. Five different steps comprise:  <ul> <li>1.1: Rule-based change classification</li> <li>1.2: Hierarchical analysis</li> <li>1.3: ML/DL change classification</li> <li>1.4: Derivation of adaptive workflows</li> <li>1.5: Continuous integration in py4dgeo</li> </ul> <p>Research target 2: Visualization of classified change events:</p>  Development of new concepts and tools for the visualization of the detected terrain changes for use by end users. Three different steps comprise:  <ul> <li>2.1: Selection of relevant changes</li> <li>2.2: 2D GIS layer</li> <li>2.3: 3D objects</li> </ul>"},{"location":"index.html#implemented-methods-and-their-potential-applications","title":"\ud83d\udca1 Implemented methods and their potential applications","text":"<ul> <li>Point cloud projection: Generate range and color images from point cloud data.</li> <li>Bi-temporal analysis: Compare point clouds from different time frames to detect changes.</li> <li>Change event management: Convert detected clusters into change events.</li> <li>Data handling: Efficiently split, append, and merge LAS/LAZ files.</li> <li>3D objects: Convert change events into 3D mesh objects.</li> <li>GIS and KML layer generation: Project 3D change events to 2D GIS and KML polygon layers with their metadata for QGIS and Google Earth visualization.</li> <li>Visualization: Quickly visualize change events on the generated range and color images.</li> </ul>"},{"location":"index.html#examples","title":"\ud83c\udfae Examples","text":"Example 1: Main AImon5.0 monitoring pipeline         Example 2: Adaptive monitoring         Example 3: Rule-based classification of change events         Example 4: Rule-based filtering of change events         Example 5: Manually labelled dataset for random forest training         Example 6: Random forest classification on prediction dataset"},{"location":"index.html#full-worfklow-implementation","title":"\ud83d\udee0\ufe0f Full worfklow implementation","text":"Serves as the entry point for the AImon5.0 processing workflow. It orchestrates the execution of various processing stages, including configuration setup, bi-temporal analysis, and change detection."},{"location":"index.html#publications","title":"\ud83d\udcda Publications","text":"Journal and conference <pre><code>@article{Tabernig2025,\n  author       = {Tabernig, Ronald and Albert, William and Weiser, Hannah and H{\\\"{o}}fle, Bernhard},\n  year         = {2025},\n  title        = {A hierarchical approach for near real-time 3D surface change analysis of permanent laser scanning point clouds},\n  doi          = {10.5445/IR/1000180377},\n  pagetotal    = {9}\n}\n</code></pre> <pre><code>@article{WeiserHoefle2025,\n  author       = {Weiser, Hannah and H{\\\"{o}}fle, Bernhard},\n  journal      = {EarthArXiv},\n  year         = {2025},\n  title        = {Advancing vegetation monitoring with virtual laser scanning of dynamic scenes (VLS-4D): Opportunities, implementations and future perspectives},\n  doi          = {10.31223/X51Q5V},\n}\n</code></pre> <pre><code>@article{Albert2025,\n  author       = {Albert, William and Weiser, Hannah and Tabernig, Ronald and H{\\\"{o}}fle, Bernhard},\n  journal      = {ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences},\n  year         = {2025},\n  title        = {Wind during terrestrial laser scanning of trees: Simulation-based assessment of effects on point cloud features and leaf-wood classification},\n  doi          = {},\n  pagetotal    = {8}\n}\n</code></pre> Software <pre><code>@software{Tabernig_VAPC_-_Voxel_2024,\n  author = {Tabernig, Ronald and Albert, William and Weiser, Hannah and H{\\\"{o}}fle, Bernhard},\n  license = {MIT},\n  month = dec,\n  title = {{VAPC - Voxel Analysis for Point Clouds}},\n  url = {https://github.com/3dgeo-heidelberg/vapc},\n  version = {0.0.1},\n  year = {2024}\n}\n</code></pre> Abstract <pre><code>@inproceedings{AlbertSummerSchool2024,\n  author       = {Albert, William},\n  title        = {Considering wind effects in LiDAR simulation-based machine learning for point cloud classification in forests},\n  booktitle    = {Sensing Mountains. Innsbruck Summer School of Alpine Research 2024 \u2013 Close Range Sensing Techniques in Alpine Terrain},\n  editor       = {Rutzinger, M. and Anders, K. and Eltner, A. and Gaevert, C. and H\u00f6fle, B. and Lindenbergh, R. and Mayr, A. and Nopens, S. and Oude Elberink, S. and Pirotti, F.},\n  pages        = {19--22},\n  year         = {2024},\n  address      = {Innsbruck},\n  publisher    = {innsbruck university press (IUP)},\n  doi          = {10.15203/99106-137-3},\n  note         = {Abstract},\n  url          = {https://doi.org/10.15203/99106-137-3}\n}\n</code></pre> <pre><code>@inproceedings{TabernigSummerSchool2024,\n  author       = {Tabernig, Ronald},\n  title        = {Simulating laser scanning of dynamic virtual 3D scenes for improved 4D point cloud based topographic change analysis},\n  booktitle    = {Sensing Mountains. Innsbruck Summer School of Alpine Research 2024 \u2013 Close Range Sensing Techniques in Alpine Terrain},\n  editor       = {Rutzinger, M. and Anders, K. and Eltner, A. and Gaevert, C. and H\u00f6fle, B. and Lindenbergh, R. and Mayr, A. and Nopens, S. and Oude Elberink, S. and Pirotti, F.},\n  pages        = {134--137},\n  year         = {2024},\n  address      = {Innsbruck},\n  publisher    = {innsbruck university press (IUP)},\n  doi          = {10.15203/99106-137-3},\n  note         = {Abstract},\n  url          = {https://doi.org/10.15203/99106-137-3}\n}\n</code></pre> <pre><code>@inproceedings{Tabernig2024,\n  author       = {Tabernig, Ronald and Zahs, Vivien and Weiser, Hannah and H{\\\"{o}}fle, Bernhard},\n  title        = {Simulating 4D scenes of rockfall and landslide activity for improved 3D point cloud-based change detection using machine learning},\n  booktitle    = {EGU General Assembly 2024},\n  year         = {2024},\n  address      = {Vienna, Austria},\n  month        = apr,\n  note         = {EGU24-1613},\n  doi          = {10.5194/egusphere-egu24-1613},\n  url          = {https://doi.org/10.5194/egusphere-egu24-1613}\n}\n</code></pre> <pre><code>@inproceedings{Hofle2024,\n  author       = {H{\\\"{o}}fle, B. and Tabernig, R. and Zahs, V. and Esmor\u00eds, A.M. and Winiwarter, L. and Weiser, H.},\n  title        = {Machine-learning based 3D point cloud classification and multitemporal change analysis with simulated laser scanning data using open source scientific software},\n  booktitle    = {EGU General Assembly 2024},\n  volume       = {EGU24},\n  pages        = {1--2},\n  year         = {2024},\n  doi          = {10.5194/egusphere-egu24-1261},\n  note         = {Abstract},\n  url          = {https://doi.org/10.5194/egusphere-egu24-1261}\n}\n\n</code></pre>"},{"location":"index.html#credits","title":"\ud83d\udcc2 Credits","text":"<p>Software usage</p> <p>As a starting point, please have a look to the Jupyter Notebooks available listed in the top left corner of the page. Click here for a detailled description of the configuration file parameters.</p> <p>Citation</p> <p>Please cite the AImon5.0 repository when using our software &amp; tools in your research.</p> <pre><code>@software{AImon5.0,\nauthor = {AImon5.0 Development Core Team},\ntitle = {AImon5.0: tool for 3D point cloud processing and projection},\njournal = {},\nyear = {2025},\nnumber = {},\nvolume = {},\ndoi = {},\nurl = {https://github.com/3dgeo-heidelberg/AImon},\n}\n</code></pre> <p>Funding / acknowledgements</p> <p>The Federal Ministry of Research, Technology and Space (BMBF) was funding the AImon5.0 project within the funding measure \"Digital GreenTech \u2013 Environmental Engineering meets Digitalisation\" as part of the \"Research for Sustainability (FONA) Strategy\".</p> <p>Contact / bugs / feature requests</p>  Have you found a bug or have specific request for a new feature? Please open a new issue in the online code repository on Github. Also for general questions please use the issue system.  Scientific requests can be directed to the  3DGeo Research Group Heidelberg and its respective members.  <p>License</p> <p>This is licensed under the MIT license.</p>"},{"location":"adaptive_monitoring.html","title":"Adaptive monitoring","text":"In\u00a0[\u00a0]: Copied! <pre># importing the zipfile module \nfrom zipfile import ZipFile \nimport os\n\nhelios_root = r\"your_path_to_helios_root\"  # Replace with your actual path\n\nzip_path = r\"../test_data/data_for_aimon.zip\"\nout_folder = os.path.join(helios_root, os.path.basename(zip_path)[:-4])\n\n#Unzip the data to the helios root directory\nwith ZipFile(zip_path, 'r') as z_object: \n    # Extracting all the members of the zip  \n    # into a specific location. \n    z_object.extractall( \n        path=out_folder) \n</pre> # importing the zipfile module  from zipfile import ZipFile  import os  helios_root = r\"your_path_to_helios_root\"  # Replace with your actual path  zip_path = r\"../test_data/data_for_aimon.zip\" out_folder = os.path.join(helios_root, os.path.basename(zip_path)[:-4])  #Unzip the data to the helios root directory with ZipFile(zip_path, 'r') as z_object:      # Extracting all the members of the zip       # into a specific location.      z_object.extractall(          path=out_folder)   In\u00a0[\u00a0]: Copied! <pre># Define parameters\noutput_folder_standard_mode = r\"./out/adaptive_monitoring/standard_mode/\"  # Replace with your actual path\noutput_folder_adaptive_mode = r\"./out/adaptive_monitoring/adaptive_mode/\"  # Replace with your actual path\n\nos.makedirs(output_folder_standard_mode, exist_ok=True)\nos.makedirs(output_folder_adaptive_mode, exist_ok=True)\n\n# Run in standard mode\n!python ../src/aimon/adaptive_pipeline.py --helios_root {helios_root} --output_folder {output_folder_standard_mode}\n\n# Run in adaptive mode\n!python ../src/aimon/adaptive_pipeline.py --helios_root {helios_root} --output_folder {output_folder_adaptive_mode} --adaptive\n</pre> # Define parameters output_folder_standard_mode = r\"./out/adaptive_monitoring/standard_mode/\"  # Replace with your actual path output_folder_adaptive_mode = r\"./out/adaptive_monitoring/adaptive_mode/\"  # Replace with your actual path  os.makedirs(output_folder_standard_mode, exist_ok=True) os.makedirs(output_folder_adaptive_mode, exist_ok=True)  # Run in standard mode !python ../src/aimon/adaptive_pipeline.py --helios_root {helios_root} --output_folder {output_folder_standard_mode}  # Run in adaptive mode !python ../src/aimon/adaptive_pipeline.py --helios_root {helios_root} --output_folder {output_folder_adaptive_mode} --adaptive"},{"location":"adaptive_monitoring.html#adaptive-monitoring-pipeline","title":"Adaptive Monitoring Pipeline\u00b6","text":"<p>Adaptive recording workflows are derived to control the permanent laser scanner. The data acquisition is adapted by the system according to defined rules applied on the captured data. The spatial extent and resolution as well as the time interval of the recording can be adapted to ultimately better recognize and classify the detected changes.</p>"},{"location":"adaptive_monitoring.html#workflow-and-example","title":"Workflow and example\u00b6","text":"<p>As a proof of concept and in order to maintain generalisability and independent of specific scanning device manufacturers, we use virtual laser scanning (VLS) of dynamic 3D scenes. In standard mode, the VLS setup has the same scanner position, scan settings and interval from the study site in Trier. In adaptive mode, the extension we propose, a signal is sent to the scanner at the end of the hierarchical change analysis, indicating whether there was change between the last two epochs. If so, the field of view is restricted to the detected change and the horizontal and vertical scan resolutions are both doubled. With these settings, a recording is made at a 30 minutes interval instead of 60 minutes. In addition, for completeness, a standard scan is also recorded to ensure that no changes are missed. A 3D model of the area under investigation is used as the basic scene. We simulate a rock topple with a subsequent rock fall. We show that under given circumstances, subsequent changes can be recognised more quickly and in higher resolution.</p> <p>The following table gives an overview of the scenario that is used to test the adaptive monitoring scenario.</p> Scene name S0: Initial scene S1: Rock topple S2: Rock fall Change occurs at: No change until 12:50 At 12:50 At 13:10 Earliest detection via adaptive monitoring 12:00 13:00 13:30 Earliest detection via regular monitoring 12:00 13:00 14:00 <p>This notebook demonstrates how to run the <code>adaptive_pipeline.py</code> script with the standard and adaptive modes. It includes a single code cell to launch the simulation and change-detection pipeline.</p> <p>Key steps:</p> <ol> <li>Standard vs Adaptive Mode: Standard mode uses fixed intervals (60\u00a0min overview scans), adaptive mode reduces interval to 30\u00a0min after detecting change.</li> <li>Overview &amp; Detail Scans: Overview scan always runs; detail (high\u2010res) scan runs when change detected and FOV updated.</li> <li>Change Detection: VAPC-based change detection flags areas of significant change, triggers M3C2 and clustering.</li> <li>Parameters: Set <code>--helios_root</code>, <code>--output_folder</code>, and optionally <code>--adaptive</code>.</li> </ol>"},{"location":"adaptive_monitoring.html#adaptive-monitoring-scenario","title":"Adaptive monitoring scenario\u00b6","text":""},{"location":"adaptive_monitoring.html#install-helios-and-copy-the-test-data","title":"Install HELIOS++ and copy the test data\u00b6","text":"<ul> <li>To install pyhelios follow the instructions given at https://github.com/3dgeo-heidelberg/helios</li> <li>Using the path to the helios root you can execute the next cell to unzip the data required for the lidar simulation</li> </ul>"},{"location":"adaptive_monitoring.html#running-the-adaptive-monitoring-system","title":"Running the adaptive monitoring system\u00b6","text":"<p>The output point clouds will be generated for the standard and adaptive mode in their respective folder.</p>"},{"location":"classification_of_change_events_rule_based.html","title":"Rule-based classification of change events","text":"In\u00a0[1]: Copied! <pre>import os\nimport matplotlib.pyplot as plt\nfrom aimon import ProjectChange\nfrom aimon import ChangeEventCollection\nfrom aimon import utilities\n\n# Figure out the directory where this notebook/script lives\ntry:\n    current_dir = os.path.dirname(os.path.abspath(__file__))\nexcept NameError:\n    current_dir = os.getcwd()\n\n# Change into that directory so all relative paths resolve correctly\nos.chdir(current_dir)\n</pre> import os import matplotlib.pyplot as plt from aimon import ProjectChange from aimon import ChangeEventCollection from aimon import utilities  # Figure out the directory where this notebook/script lives try:     current_dir = os.path.dirname(os.path.abspath(__file__)) except NameError:     current_dir = os.getcwd()  # Change into that directory so all relative paths resolve correctly os.chdir(current_dir) In\u00a0[2]: Copied! <pre># Path to the unlabelled change events test file\nchange_events_file = \"../test_data/change_events_unlabelled.json\"\n\n# Folder where the labelled output will go\noutfolder = \"../test_data/out\"\n\n# Full path for the labelled file\nlabelled_file = os.path.join(outfolder, 'change_events_labelled_rule_based.json')\n</pre> # Path to the unlabelled change events test file change_events_file = \"../test_data/change_events_unlabelled.json\"  # Folder where the labelled output will go outfolder = \"../test_data/out\"  # Full path for the labelled file labelled_file = os.path.join(outfolder, 'change_events_labelled_rule_based.json') In\u00a0[3]: Copied! <pre>classification_rules = {\n    \"large_change\": {\n         \"change_mean\": {\"min\": 0.2, \"max\": 10},\n         \"hull_volume\": {\"min\": 100}\n    },\n    \"small_change\": {\n         \"change_mean\": {\"max\": 0.2}\n    },\n    \"specific_change\": {\n         \"change_mean\": {\"min\": 1, \"max\": 5},\n         \"hull_volume\": {\"min\": 5, \"max\": 10}\n    },\n}\n</pre> classification_rules = {     \"large_change\": {          \"change_mean\": {\"min\": 0.2, \"max\": 10},          \"hull_volume\": {\"min\": 100}     },     \"small_change\": {          \"change_mean\": {\"max\": 0.2}     },     \"specific_change\": {          \"change_mean\": {\"min\": 1, \"max\": 5},          \"hull_volume\": {\"min\": 5, \"max\": 10}     }, } In\u00a0[4]: Copied! <pre># Load events from file\ncoll = ChangeEventCollection().load_from_file(change_events_file)\n\n# Apply our rule\u2011based classifier to produce a DataFrame of features + event_type\nfeatures_df = coll.classify_events_rule_based(classification_rules)\n\n# Write the labelled events back out\ncoll.save_to_file(labelled_file)\n</pre> # Load events from file coll = ChangeEventCollection().load_from_file(change_events_file)  # Apply our rule\u2011based classifier to produce a DataFrame of features + event_type features_df = coll.classify_events_rule_based(classification_rules)  # Write the labelled events back out coll.save_to_file(labelled_file) In\u00a0[5]: Copied! <pre># Helper to plot a subset\ndef plot_events(df, event_type, color, alpha=0.7, size=5):\n    subset = df[df['event_type'] == event_type]\n    plt.scatter(subset['change_mean'], subset['hull_volume'],\n                label=event_type.replace('_', ' ').title(),\n                alpha=alpha, s=size, color=color)\n\nplt.figure(figsize=(5, 4))\n\nplot_events(features_df, 'large_change',   'red')\nplot_events(features_df, 'small_change',   'blue')\nplot_events(features_df, 'specific_change','green')\nplot_events(features_df, 'unclassified',   'gray', alpha=0.3)\n\nplt.yscale('log')\nplt.legend()\nplt.xlabel('Change Mean')\nplt.ylabel('Hull Volume')\nplt.title('Rule\u2011based Classification of Change Events')\nplt.show()\n</pre> # Helper to plot a subset def plot_events(df, event_type, color, alpha=0.7, size=5):     subset = df[df['event_type'] == event_type]     plt.scatter(subset['change_mean'], subset['hull_volume'],                 label=event_type.replace('_', ' ').title(),                 alpha=alpha, s=size, color=color)  plt.figure(figsize=(5, 4))  plot_events(features_df, 'large_change',   'red') plot_events(features_df, 'small_change',   'blue') plot_events(features_df, 'specific_change','green') plot_events(features_df, 'unclassified',   'gray', alpha=0.3)  plt.yscale('log') plt.legend() plt.xlabel('Change Mean') plt.ylabel('Hull Volume') plt.title('Rule\u2011based Classification of Change Events') plt.show()  In\u00a0[6]: Copied! <pre>img_path = \"../test_data/RangeImage.tif\"\n\nchange_prj = ProjectChange(\n    change_event_file       = labelled_file,\n    project_name            = os.path.basename(labelled_file)[:-5],\n    projected_image_path    = img_path,\n    projected_events_folder = outfolder,\n    epsg                    = 31254\n)\n\nchange_prj.project_change()\n</pre> img_path = \"../test_data/RangeImage.tif\"  change_prj = ProjectChange(     change_event_file       = labelled_file,     project_name            = os.path.basename(labelled_file)[:-5],     projected_image_path    = img_path,     projected_events_folder = outfolder,     epsg                    = 31254 )  change_prj.project_change() In\u00a0[\u00a0]: Copied! <pre># Paths to the vector and raster files\nchange_event_file = \"../test_data/out/change_events_labelled_rule_based_change_events_pixel.geojson\"\n\nutilities.plot_change_events(change_event_file, img_path, 'event_type', ['#8080FF', 'green', '#8B4513', '#B5179E'])\n</pre> # Paths to the vector and raster files change_event_file = \"../test_data/out/change_events_labelled_rule_based_change_events_pixel.geojson\"  utilities.plot_change_events(change_event_file, img_path, 'event_type', ['#8080FF', 'green', '#8B4513', '#B5179E'])"},{"location":"classification_of_change_events_rule_based.html#rule-based-classification-of-change-events","title":"Rule-based classification of change events\u00b6","text":"<p>This Jupyter Notebook demonstrates a rule-based classification workflow for analyzing change events. The notebook processes unlabelled change events, applies predefined classification rules, and generates labeled outputs.</p>"},{"location":"classification_of_change_events_rule_based.html#workflow","title":"Workflow\u00b6","text":"<ol> <li><p>Setup and Configuration:</p> <ul> <li>Import necessary modules.</li> <li>Set the working directory to ensure relative paths resolve correctly.</li> </ul> </li> <li><p>Input/Output Paths:</p> <ul> <li>Define the path to the unlabelled change events file (<code>change_events_file</code>).</li> <li>Specify the output folder (<code>outfolder</code>) and the path for the labeled output file (<code>labelled_file</code>).</li> </ul> </li> <li><p>Classification Rules:</p> <ul> <li>Define a dictionary of rules (<code>classification_rules</code>) to classify events based on features such as <code>change_mean</code> and <code>hull_volume</code>.</li> </ul> </li> <li><p>Processing:</p> <ul> <li>Load the unlabelled change events into a <code>ChangeEventCollection</code> object (<code>coll</code>).</li> <li>Apply the rule-based classifier to generate a labeled DataFrame (<code>features_df</code>).</li> <li>Save the labeled events to the specified output file.</li> </ul> </li> <li><p>Visualization:</p> <ul> <li>Plot the classified events using scatter plots, with different colors representing different event types.</li> </ul> </li> </ol>"},{"location":"classification_of_change_events_rule_based.html#outputs","title":"Outputs\u00b6","text":"<ul> <li>Labeled Events File: A JSON file (<code>labelled_file</code>) containing the classified change events.</li> <li>Visualization: A scatter plot showing the distribution of classified events based on their features.</li> </ul>"},{"location":"classification_of_change_events_rule_based.html#imports-working-directory","title":"Imports &amp; working directory\u00b6","text":"<p>In order to ensure all imports are available and that paths are relative to this script\u2019s location, we first import modules and set the working directory.</p>"},{"location":"classification_of_change_events_rule_based.html#define-inputoutput-paths","title":"Define input/output paths\u00b6","text":"<p>Next we declare where to read our unlabelled events from, and where to write the labelled output.</p>"},{"location":"classification_of_change_events_rule_based.html#classification-rules-definition","title":"Classification rules definition\u00b6","text":"<p>Each rule is a mapping from feature names (e.g. change_mean) to a dict with optional \"min\" and/or \"max\" bounds. If an event satisfies all bounds for a rule, it is assigned that class.  \"class_name\": { \"feature1\": {\"min\": &lt;lower_bound&gt;, \"max\": &lt;upper_bound&gt;}, \"feature2\": {\"min\": &lt;lower_bound&gt;} }</p>"},{"location":"classification_of_change_events_rule_based.html#load-classify-save","title":"Load, classify &amp; save\u00b6","text":"<p>With paths and rules in place, we load the unlabelled events, apply the rule\u2011based classifier, and save the results.</p>"},{"location":"classification_of_change_events_rule_based.html#visualize-events-clustering","title":"Visualize events clustering\u00b6","text":"<p>Finally, we plot each class with a different color and use a log scale on the y\u2011axis to handle wide ranges of hull volumes.</p>"},{"location":"classification_of_change_events_rule_based.html#project-changes-into-gis-format","title":"Project changes into GIS format\u00b6","text":"<p>Finally, we wrap up by projecting our labelled events into GeoJSON using ProjectChange.</p>"},{"location":"classification_of_change_events_using_random_forest_classifier.html","title":"Random forest classification of change events","text":"In\u00a0[1]: Copied! <pre>from aimon import ProjectChange\nfrom aimon import ChangeEventCollection\nfrom aimon import utilities\nimport os\n# Set current directory to the location of the notebook (works even if __file__ is not defined)\ntry:\n    current_dir = os.path.dirname(os.path.abspath(__file__))\nexcept NameError:\n    current_dir = os.getcwd()\n\nos.chdir(current_dir)\n</pre> from aimon import ProjectChange from aimon import ChangeEventCollection from aimon import utilities import os # Set current directory to the location of the notebook (works even if __file__ is not defined) try:     current_dir = os.path.dirname(os.path.abspath(__file__)) except NameError:     current_dir = os.getcwd()  os.chdir(current_dir) In\u00a0[2]: Copied! <pre># Input files and output folder\nlabelled_file    = \"../test_data/change_events_labelled.json\"\nunlabelled_file  = \"../test_data/change_events_unlabelled.json\"\noutfolder        = \"../test_data/out\"\nos.makedirs(outfolder, exist_ok=True)\n\n# Train/test split\ntest_size       = 0.2\nrandom_state    = 3\n\nparam_grid = {\n    'n_estimators':       [50, 100, 200],\n    'max_depth':          [None, 5, 10, 20, 30],\n    'min_samples_split':  [2, 5, 10],\n    'min_samples_leaf':   [1, 2, 4],\n    'max_features':       ['sqrt', 'log2', None],\n    'bootstrap':          [True]\n}\n\n# Labels to ignore during training\nignore_labels = [\"undefined\"]\n\n# Paths for outputs\npredicted_file = os.path.join(outfolder, \"change_events_labelled_using_random_forest.json\")\nmodel_file     = os.path.join(outfolder, \"best_model.joblib\")\n</pre> # Input files and output folder labelled_file    = \"../test_data/change_events_labelled.json\" unlabelled_file  = \"../test_data/change_events_unlabelled.json\" outfolder        = \"../test_data/out\" os.makedirs(outfolder, exist_ok=True)  # Train/test split test_size       = 0.2 random_state    = 3  param_grid = {     'n_estimators':       [50, 100, 200],     'max_depth':          [None, 5, 10, 20, 30],     'min_samples_split':  [2, 5, 10],     'min_samples_leaf':   [1, 2, 4],     'max_features':       ['sqrt', 'log2', None],     'bootstrap':          [True] }  # Labels to ignore during training ignore_labels = [\"undefined\"]  # Paths for outputs predicted_file = os.path.join(outfolder, \"change_events_labelled_using_random_forest.json\") model_file     = os.path.join(outfolder, \"best_model.joblib\")  In\u00a0[3]: Copied! <pre># Load labelled events collection\ncoll = ChangeEventCollection.load_from_file(labelled_file)\n\n# Train RF with grid search, holding out a test split\ncoll.train_random_forest(\n    ignore_labels=ignore_labels,\n    param_grid=param_grid,\n    test_size=test_size,\n    random_state=random_state\n)\n</pre> # Load labelled events collection coll = ChangeEventCollection.load_from_file(labelled_file)  # Train RF with grid search, holding out a test split coll.train_random_forest(     ignore_labels=ignore_labels,     param_grid=param_grid,     test_size=test_size,     random_state=random_state )  <pre>Best params: {'bootstrap': True, 'max_depth': None, 'max_features': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\nTrain  F1: 0.9907858772167454\nTest   F1: 0.8020458003042678\n\nClassification Report:\n                           precision    recall  f1-score   support\n\ngravitationalMassMovement       0.84      0.82      0.83       366\n               vegetation       0.76      0.79      0.78       272\n\n                 accuracy                           0.81       638\n                macro avg       0.80      0.80      0.80       638\n             weighted avg       0.81      0.81      0.81       638\n\n</pre> <pre>Jaccard Score:                  0.670\nAccuracy Score:                 0.806\nF1 Score (macro):               0.802\nMatthews Corr. Coef.:           0.604\nCohen's Kappa:                  0.604\n</pre> In\u00a0[4]: Copied! <pre># Persist the trained model\ncoll.save_model(model_file)\n\n# (Later or elsewhere) reload it\ncoll.load_model(model_file)\n</pre> # Persist the trained model coll.save_model(model_file)  # (Later or elsewhere) reload it coll.load_model(model_file) <pre>Model saved to ../test_data/out\\best_model.joblib\nModel loaded from ../test_data/out\\best_model.joblib\n</pre> In\u00a0[5]: Copied! <pre># Load unlabelled events, attach trained model, and classify\nunlabelled_coll = ChangeEventCollection.load_from_file(unlabelled_file)\nunlabelled_coll.model = coll.model\nunlabelled_coll.apply_random_forest()\n\n# Save predictions to JSON\nunlabelled_coll.save_to_file(predicted_file)\n</pre> # Load unlabelled events, attach trained model, and classify unlabelled_coll = ChangeEventCollection.load_from_file(unlabelled_file) unlabelled_coll.model = coll.model unlabelled_coll.apply_random_forest()  # Save predictions to JSON unlabelled_coll.save_to_file(predicted_file) In\u00a0[6]: Copied! <pre>img_path  = \"../test_data/RangeImage.tif\"\nchange_prj = ProjectChange(\n    change_event_file       = predicted_file,\n    project_name            = os.path.basename(predicted_file)[:-5],\n    projected_image_path    = img_path,\n    projected_events_folder = outfolder,\n    epsg                    = 31254\n)\n\nchange_prj.project_change()\n</pre> img_path  = \"../test_data/RangeImage.tif\" change_prj = ProjectChange(     change_event_file       = predicted_file,     project_name            = os.path.basename(predicted_file)[:-5],     projected_image_path    = img_path,     projected_events_folder = outfolder,     epsg                    = 31254 )  change_prj.project_change() In\u00a0[\u00a0]: Copied! <pre># Paths to the vector and raster files\nchange_event_file = \"../test_data/out/change_events_labelled_using_random_forest_change_events_pixel.geojson\"\n\nutilities.plot_change_events(change_event_file, img_path, 'event_type', ['#8B4513', 'green'])\n</pre> # Paths to the vector and raster files change_event_file = \"../test_data/out/change_events_labelled_using_random_forest_change_events_pixel.geojson\"  utilities.plot_change_events(change_event_file, img_path, 'event_type', ['#8B4513', 'green'])"},{"location":"classification_of_change_events_using_random_forest_classifier.html#random-forest-based-event-classification-workflow","title":"Random Forest-Based Event Classification Workflow\u00b6","text":"<p>This notebook demonstrates a complete workflow for classifying change events using a Random Forest (RF) model. The process involves loading labelled and unlabelled data, training a model, and applying it to classify unlabelled events. The results are saved and projected into a GIS-compatible format for further analysis.</p>"},{"location":"classification_of_change_events_using_random_forest_classifier.html#workflow","title":"Workflow\u00b6","text":"<ol> <li>Setup: Import necessary modules and set the working directory.</li> <li>Configuration: Define input/output file paths, hyperparameters, and other constants.</li> <li>Model Training: Train a Random Forest model on labelled change events using grid search for hyperparameter tuning.</li> <li>Model Persistence: Save the trained model to disk and demonstrate reloading it.</li> <li>Classification: Apply the trained model to classify unlabelled change events and save the predictions.</li> <li>GIS Projection: Convert the classified events into a GeoJSON format for GIS visualization.</li> </ol>"},{"location":"classification_of_change_events_using_random_forest_classifier.html#outputs","title":"Outputs\u00b6","text":"<ul> <li><code>change_events_labelled_using_random_forest.json</code>: Classified change events with predicted labels.</li> <li><code>best_model.joblib</code>: Trained Random Forest model.</li> <li>GeoJSON files: GIS-compatible projections of classified events.</li> </ul> <p>This notebook provides a structured approach to event classification and GIS integration, ensuring reproducibility and scalability.</p>"},{"location":"classification_of_change_events_using_random_forest_classifier.html#imports-working-directory","title":"Imports &amp; Working Directory\u00b6","text":"<p>In order to ensure all imports are available and that paths are relative to this script\u2019s location, we first import modules and set the working directory.</p>"},{"location":"classification_of_change_events_using_random_forest_classifier.html#define-paths-hyperparameters","title":"Define Paths &amp; Hyperparameters\u00b6","text":"<p>To keep configuration in one place, we declare input/output file paths, the RF hyperparameter grid, and other constants.</p>"},{"location":"classification_of_change_events_using_random_forest_classifier.html#train-random-forest-on-labelled-data","title":"Train Random Forest on Labelled Data\u00b6","text":"<p>In order to build a model for event classification, we load the labelled events and run a grid\u2011search RF.</p>"},{"location":"classification_of_change_events_using_random_forest_classifier.html#save-reload-the-trained-model","title":"Save &amp; Reload the Trained Model\u00b6","text":"<p>To keep our best model for later reuse, we save it to disk, then demonstrate loading it back.</p>"},{"location":"classification_of_change_events_using_random_forest_classifier.html#classify-unlabelled-events-save","title":"Classify Unlabelled Events &amp; Save\u00b6","text":"<p>With a trained RF loaded into memory, we apply it to previously unlabelled events and write out the new labels.</p>"},{"location":"classification_of_change_events_using_random_forest_classifier.html#project-changes-into-gis-format","title":"Project Changes into GIS Format\u00b6","text":"<p>Finally, we wrap up by projecting our labelled events into GeoJSON using ProjectChange.</p>"},{"location":"configuration_description.html","title":"Configuration Description","text":"<p>This document details each configuration parameter and its role in the processing pipeline for point cloud change detection. The pipeline integrates voxelization (VAPC), change analysis via M3C2 (py4dgeo), clustering, and projections for visualization. The settings described below are used across various modules to ensure reproducibility.</p> <p>For each parameter, the allowed formats are indicated. When a parameter is fixed to a set of options, those acceptable values are listed.</p> <p>In summary, the configuration parameters described bellow establish a framework for point cloud analysis:</p> <ul> <li>Global project settings define naming, logging, and file output behaviors.</li> <li>VAPC settings determine voxelization parameters and computational procedures for extracting meaningful geometric properties.</li> <li>M3C2 settings include corepoint generation, normal computation, and registration errors to facilitate precise change quantification.</li> <li>Clustering parameters aggregate significant changes into spatially coherent groups.</li> <li>Point cloud projection parameters ensure that processed data is accurately visualized and georeferenced.</li> </ul> <p>Collectively, these settings enable a workflow for detecting, quantifying, and visualizing changes in 3D time series datasets.</p> Example of a configuration file <pre><code>{\n    \"project_setting\": {\n        \"project_name\": \"Trier_vs6_av0_999\",\n        \"output_folder\": \"./test_data/out\",\n        \"temporal_format\": \"%y%m%d_%H%M%S\",\n        \"silent_mode\": true,\n        \"include_timestamp\": false\n    },\n    \"vapc_settings\": {\n        \"vapc_config\": {\n            \"voxel_size\": 6,\n            \"origin\": [\n                0, 0, 0\n            ],\n            \"attributes\": {},\n            \"filter\": {\n                \"filter_attribute\": \"point_count\",\n                \"min_max_eq\": \"greater_than\",\n                \"filter_value\": 30\n            },\n            \"compute\": [],\n            \"return_at\": \"center_of_gravity\"\n        },\n        \"bi_temporal_vapc_config\": {\n            \"signicance_threshold\": 0.999\n        },\n        \"vapc_mask\": {\n            \"buffer_size\": 0\n        }\n    },\n    \"m3c2_settings\": {\n        \"corepoints\": {\n            \"use\": false,\n            \"point_spacing_m\": 1\n        },\n        \"m3c2\": {\n            \"normal_radii\": [\n                1, 2, 3\n            ],\n            \"cyl_radii\": 1,\n            \"max_distance\": 10.0,\n            \"registration_error\": 0.02\n        }\n    },\n    \"cluster_settings\": {\n        \"cluster_method\": \"DBSCAN\",\n        \"distance_threshold\": 1,\n        \"cluster_by\": [\n            \"X\", \"Y\", \"Z\"\n        ],\n        \"min_cluster_size\": 100\n    },\n    \"pc_projection\": {\n        \"pc_path\": \"./test_data/240826_000005.laz\",\n        \"make_range_image\": true,\n        \"make_color_image\": false,\n        \"create_kml\": true,\n        \"top_view\": false,\n        \"resolution_cm\": 15.0,\n        \"camera_position\": [\n            330599.6068, 5515785.9140, 135.4113\n        ],\n        \"rgb_light_intensity\": 100,\n        \"range_light_intensity\": 15,\n        \"epsg\": 32632\n    }\n}\n</code></pre>"},{"location":"configuration_description.html#project_setting","title":"project_setting","text":"<ul> <li> <p>project_name:   This specifies the project identifier (e.g. <code>Trier_vs6_av0_999</code>).   Allowed format: Any non-empty string; typically alphanumeric with underscores or hyphens.   All outputs are stored in a subdirectory with the same name as the project within the designated output folder.</p> </li> <li> <p>output_folder:   The base directory where all output files are stored (e.g., <code>./test_data/out</code>). Allowed format: A valid relative or absolute file path as a string.</p> </li> <li> <p>temporal_format:   A date-time formatting string (e.g., <code>%y%m%d_%H%M%S</code>) used for parsing timestamps from filenames and for generating consistent output file names. Allowed format: Formats compatible with Python\u2019s <code>strftime</code> and <code>strptime</code>; only valid format specifiers (e.g., <code>%Y</code>, <code>%m</code>, <code>%d</code>, <code>%H</code>, <code>%M</code>, <code>%S</code>) are accepted.</p> </li> <li> <p>silent_mode:   If set to <code>true</code>, the process minimizes console output. Allowed format: Boolean (<code>true</code> or <code>false</code>).</p> </li> <li> <p>include_timestamp:   When enabled, appends timestamps to output folder. If disabled, previous outputs may be overwritten. Allowed format: Boolean (<code>true</code> or <code>false</code>).</p> </li> </ul>"},{"location":"configuration_description.html#vapc_settings","title":"vapc_settings","text":"vapc_config <ul> <li> <p>voxel_size:   Defines the size of voxels used to subdivide the point cloud. Smaller voxels result in higher spatial resolution at increased computational cost, while larger voxels aggregate more points. Allowed format: A positive float.</p> </li> <li> <p>origin:   A three-dimensional coordinate <code>[x, y, z]</code> that establishes the reference point for the voxel grid. Defaults to <code>[0, 0, 0]</code>. Allowed format: A list or array of three numeric values (floats or integers).</p> </li> <li> <p>attributes:   A dictionary serving as a placeholder for supplemental parameters (e.g., intensity averaging) required during preprocessing. Allowed format: A JSON/dictionary with string keys and corresponding values.</p> </li> <li> <p>filter:</p> <ul> <li>filter_attribute: The DataFrame column used to filter voxels. For example, <code>\"point_count\"</code> restricts processing to voxels that meet a specified point density. Allowed format: A string representing a valid column name.</li> <li>min_max_eq: The comparison operator (e.g., <code>\"greater_than\"</code>, <code>\"==\"</code>, <code>\"&lt;\"</code>, etc.) that quantifies how the attribute is compared against a threshold. Allowed options: <code>\"equal_to\"</code>, <code>\"==\"</code>, <code>\"not_equal_to\"</code>, <code>\"!=\"</code>, <code>\"greater_than\"</code>, <code>\"&gt;\"</code>, <code>\"greater_than_or_equal_to\"</code>, <code>\"&gt;=\"</code>, <code>\"less_than\"</code>, <code>\"&lt;\"</code>, <code>\"less_than_or_equal_to\"</code>, <code>\"&lt;=\"</code>.</li> <li>filter_value: Numeric threshold (e.g., 30) applied to the corresponding attribute to select voxels for further analysis. Allowed format: An integer or float, matching the data type of the attribute field.</li> </ul> </li> <li> <p>compute:   A list of computational operations to be executed for each voxel. Allowed options: A list of strings from a fixed set such as <code>\"voxel_index\"</code>, <code>\"point_count\"</code>, <code>\"point_density\"</code>, <code>\"percentage_occupied\"</code>, <code>\"covariance_matrix\"</code>, <code>\"eigenvalues\"</code>, <code>\"geometric_features\"</code>, <code>\"center_of_gravity\"</code>, <code>\"distance_to_center_of_gravity\"</code>, <code>\"std_of_cog\"</code>, <code>\"closest_to_center_of_gravity\"</code>, <code>\"center_of_voxel\"</code>, <code>\"corner_of_voxel\"</code>.</p> </li> <li> <p>return_at:   Indicates which computed attribute should represent the voxel\u2019s location. For instance, using <code>\"center_of_gravity\"</code> selects the voxel centroid as the representative coordinate. Allowed options: A string value chosen from the attributes computed (e.g., <code>\"center_of_gravity\"</code>, <code>\"closest_to_center_of_gravity\"</code>, etc).</p> </li> </ul> bi_temporal_vapc_config <ul> <li>signicance_threshold:   A statistical threshold (e.g., 0.999) used during bi-temporal comparisons. This value is often used alongside measures such as the Mahalanobis distance to determine whether changes observed between epochs are statistically significant. Allowed format: A float between 0 and 1.</li> </ul> vapc_mask <ul> <li>buffer_size:   Specifies an optional buffer zone (in voxel units) around the computed grid to accommodate edge effects. A zero value indicates no additional padding. Allowed format: A non-negative integer.</li> </ul> <p>Additional Context: The VAPC module performs voxelization and computes metrics (e.g., covariance matrices, eigenvalues) essential for detecting subtle geometric variations. These voxel properties underpin change detection procedures implemented in the change analysis modules.</p>"},{"location":"configuration_description.html#m3c2_settings","title":"m3c2_settings","text":"corepoints <ul> <li> <p>use:   Boolean flag indicating whether to generate a reduced subset of core points from the voxelized data. If set to <code>false</code>, analysis utilizes the full or pre-voxelized point set. Allowed format: Boolean (<code>true</code> or <code>false</code>).</p> </li> <li> <p>point_spacing_m:   Specifies the inter-point spacing (in meters) for core points. Smaller spacing yields a denser representation, which may improve resolution at the expense of increased computational load. Allowed format: A positive float.</p> </li> </ul> m3c2 <ul> <li> <p>normal_radii:   A list (e.g., <code>[1, 2, 3]</code>) defining the radii used to calculate surface normals at multiple scales. These normals capture local surface orientations, crucial for quantifying changes. Allowed format: A list of positive floats.</p> </li> <li> <p>cyl_radii:   Sets the radius of the cylindrical neighborhood used in M3C2 distance computation. This parameter influences the selection of points for comparing corresponding regions across epochs. Allowed format: A positive float.</p> </li> <li> <p>max_distance:   The maximum allowable distance for point comparisons. Allowed format: A positive float.</p> </li> <li> <p>registration_error:   The computed error when aligning the two point cloud datasets. Allowed format: A positive float, typically derived from registration uncertainty measurements.</p> </li> </ul> <p>Additional Context: The M3C2 analysis uses these settings to compute precise distance measures and to quantify uncertainties (e.g., level-of-detection values) that inform subsequent clustering and change detection.</p>"},{"location":"configuration_description.html#cluster_settings","title":"cluster_settings","text":"<ul> <li> <p>cluster_method:   Specifies the clustering algorithm used to aggregate significant change detections. DBSCAN is typically employed, although alternative methods, such as connected components, are supported. Allowed options: <code>\"DBSCAN\"</code> or <code>\"connected_components\"</code>.</p> </li> <li> <p>distance_threshold:   The maximum distance within which points are considered part of the same cluster. This parameter is analogous to the \u201ceps\u201d parameter in DBSCAN. Allowed format: A positive float.</p> </li> <li> <p>cluster_by:   Defines which dimensions (commonly X, Y, and Z coordinates) are used during the clustering process. Allowed format: A list of strings. Fixed options are typically <code>\"X\"</code>, <code>\"Y\"</code>, and <code>\"Z\"</code>.</p> </li> <li> <p>min_cluster_size:   The minimum number of points required for a group to be recognized as a valid cluster. Clusters with fewer points are deemed insignificant. Allowed format: A positive integer.</p> </li> </ul> <p>Additional Context: Clustering, as implemented, aggregates spatially correlated change detections into meaningful groups for further analysis or visualization.</p>"},{"location":"configuration_description.html#pc_projection","title":"pc_projection","text":"<ul> <li> <p>pc_path:   The file path to the input point cloud (e.g., <code>./test_data/240826_000005.laz</code>). Allowed format: A valid file path string; the file must exist and be in LAS/LAZ format.</p> </li> <li> <p>make_range_image:   Boolean flag to create a range image from the point cloud. Allowed format: Boolean (<code>true</code> or <code>false</code>).</p> </li> <li> <p>make_color_image:   Specifies whether to generate a color image from the point cloud data. Allowed format: Boolean (<code>true</code> or <code>false</code>).</p> </li> <li> <p>create_kml:   If <code>true</code>, a KML file is generated to facilitate rapid geospatial visualization. Allowed format: Boolean (<code>true</code> or <code>false</code>).</p> </li> <li> <p>top_view:   Indicates whether a top-down (bird\u2019s-eye) view is produced in the projection. Allowed format: Boolean (<code>true</code> or <code>false</code>).</p> </li> <li> <p>resolution_cm:   Specifies the resolution (in centimeters) of the output image\u2014the lower the value, the higher the resolution. Allowed format: A positive float.</p> </li> <li> <p>camera_position:   The [x, y, z] coordinates defining the camera\u2019s viewpoint for rendering, which directly impacts the visualization perspective. Allowed format: A list or array of three numeric values (floats or integers).</p> </li> <li> <p>rgb_light_intensity and range_light_intensity:   Control the intensity of lighting in the RGB and range images, respectively. Allowed format: Positive integers or floats, typically defined within a practical range (e.g., 0\u2013255 for RGB).</p> </li> <li> <p>epsg:   The EPSG code representing the coordinate reference system of the point cloud data (e.g., 32632). Allowed format: An integer corresponding to a valid EPSG code.</p> </li> </ul> <p>Additional Context: Projection settings are essential for generating accurate visual representations. They ensure that spatial data is correctly rendered and georeferenced for analysis and reporting.</p>"},{"location":"filtering_of_change_events_rule_based.html","title":"Rule-based filtering of change events","text":"In\u00a0[1]: Copied! <pre>import os\nimport matplotlib.pyplot as plt\nfrom aimon import ProjectChange\nfrom aimon import ChangeEventCollection\nfrom aimon import utilities\n\n# Set current directory to the location of the notebook (works even if __file__ is not defined)\ntry:\n    current_dir = os.path.dirname(os.path.abspath(__file__))\nexcept NameError:\n    current_dir = os.getcwd()\n\nos.chdir(current_dir)\n</pre> import os import matplotlib.pyplot as plt from aimon import ProjectChange from aimon import ChangeEventCollection from aimon import utilities  # Set current directory to the location of the notebook (works even if __file__ is not defined) try:     current_dir = os.path.dirname(os.path.abspath(__file__)) except NameError:     current_dir = os.getcwd()  os.chdir(current_dir) In\u00a0[2]: Copied! <pre># Path to the unlabelled change events and output folder\nchange_events_file = \"../test_data/change_events_unlabelled.json\"\noutfolder          = \"../test_data/out\"\nos.makedirs(outfolder, exist_ok=True)\n\nfilter_rule = {\n    \"change_mean\": {\"min\": 5, \"max\": 10}\n    }\n\n# Where to save the filtered events\nfiltered_file = os.path.join(outfolder, 'change_events_filtered_rule_based.json')\n</pre> # Path to the unlabelled change events and output folder change_events_file = \"../test_data/change_events_unlabelled.json\" outfolder          = \"../test_data/out\" os.makedirs(outfolder, exist_ok=True)  filter_rule = {     \"change_mean\": {\"min\": 5, \"max\": 10}     }  # Where to save the filtered events filtered_file = os.path.join(outfolder, 'change_events_filtered_rule_based.json')  In\u00a0[3]: Copied! <pre># Load all change events\ncoll = ChangeEventCollection().load_from_file(change_events_file)\n\n# Convert to DataFrame and keep a copy of the unfiltered data\ncoll.to_dataframe()\nunfiltered_df = coll.df\n\n# Apply rule-based filtering\ncoll.events = coll.filter_events_rule_based(filter_rule)\n# Save the filtered subset to JSON\ncoll.save_to_file(filtered_file)\n_ = coll.to_dataframe()\n</pre> # Load all change events coll = ChangeEventCollection().load_from_file(change_events_file)  # Convert to DataFrame and keep a copy of the unfiltered data coll.to_dataframe() unfiltered_df = coll.df  # Apply rule-based filtering coll.events = coll.filter_events_rule_based(filter_rule) # Save the filtered subset to JSON coll.save_to_file(filtered_file) _ = coll.to_dataframe()  In\u00a0[4]: Copied! <pre># Helper to plot a subset\ndef plot_events(df, event_type, color, alpha=0.7, size=5):\n    subset = df[df['event_type'] == event_type]\n    plt.scatter(\n        subset['change_mean'],\n        subset['hull_volume'],\n        label=event_type.replace('_', ' ').title(),\n        alpha=alpha,\n        s=size,\n        color=color\n    )\n\n# Tag the full (to\u2011be\u2011removed) and filtered DFs\nunfiltered_labeled = unfiltered_df.assign(event_type='unfiltered_data')\nfiltered_labeled   = coll.df.assign(event_type='remaining_data')\n\nplt.figure(figsize=(5, 4))\nplot_events(unfiltered_labeled,   'unfiltered_data',   color='black', alpha=0.3, size=1)\nplot_events(filtered_labeled,     'remaining_data', color='green',           size=5)\n\nplt.yscale('log')\nplt.legend()\nplt.xlabel('Change Mean')\nplt.ylabel('Hull Volume')\nplt.title('Filtered Change Events')\nplt.show()\n</pre> # Helper to plot a subset def plot_events(df, event_type, color, alpha=0.7, size=5):     subset = df[df['event_type'] == event_type]     plt.scatter(         subset['change_mean'],         subset['hull_volume'],         label=event_type.replace('_', ' ').title(),         alpha=alpha,         s=size,         color=color     )  # Tag the full (to\u2011be\u2011removed) and filtered DFs unfiltered_labeled = unfiltered_df.assign(event_type='unfiltered_data') filtered_labeled   = coll.df.assign(event_type='remaining_data')  plt.figure(figsize=(5, 4)) plot_events(unfiltered_labeled,   'unfiltered_data',   color='black', alpha=0.3, size=1) plot_events(filtered_labeled,     'remaining_data', color='green',           size=5)  plt.yscale('log') plt.legend() plt.xlabel('Change Mean') plt.ylabel('Hull Volume') plt.title('Filtered Change Events') plt.show()  In\u00a0[5]: Copied! <pre>predicted_file = os.path.join(\"../test_data\", 'change_events_unlabelled.json')\n\nimg_path = \"../test_data/RangeImage.tif\"\nchange_prj = ProjectChange(\n    change_event_file       = predicted_file,\n    project_name            = os.path.basename(predicted_file)[:-5],\n    projected_image_path    = img_path,\n    projected_events_folder = outfolder,\n    epsg                    = 31254\n)\n\nchange_prj.project_change()\n</pre> predicted_file = os.path.join(\"../test_data\", 'change_events_unlabelled.json')  img_path = \"../test_data/RangeImage.tif\" change_prj = ProjectChange(     change_event_file       = predicted_file,     project_name            = os.path.basename(predicted_file)[:-5],     projected_image_path    = img_path,     projected_events_folder = outfolder,     epsg                    = 31254 )  change_prj.project_change() In\u00a0[\u00a0]: Copied! <pre>change_event_file = \"../test_data/out/change_events_unlabelled_change_events_pixel.geojson\"\n\nutilities.plot_change_events(change_event_file, img_path, 'event_type')\n</pre> change_event_file = \"../test_data/out/change_events_unlabelled_change_events_pixel.geojson\"  utilities.plot_change_events(change_event_file, img_path, 'event_type') In\u00a0[7]: Copied! <pre>change_prj = ProjectChange(\n    change_event_file       = filtered_file,\n    project_name            = os.path.basename(filtered_file)[:-5],\n    projected_image_path    = img_path,\n    projected_events_folder = outfolder,\n    epsg                    = 31254\n)\n\nchange_prj.project_change()\n</pre> change_prj = ProjectChange(     change_event_file       = filtered_file,     project_name            = os.path.basename(filtered_file)[:-5],     projected_image_path    = img_path,     projected_events_folder = outfolder,     epsg                    = 31254 )  change_prj.project_change() In\u00a0[8]: Copied! <pre># Paths to the vector and raster files\nvector2 = \"../test_data/out/change_events_filtered_rule_based_change_events_pixel.geojson\"\n\nutilities.plot_change_events(vector2, img_path, 'event_type')\n</pre> # Paths to the vector and raster files vector2 = \"../test_data/out/change_events_filtered_rule_based_change_events_pixel.geojson\"  utilities.plot_change_events(vector2, img_path, 'event_type')"},{"location":"filtering_of_change_events_rule_based.html#rule-based-filtering-of-change-events","title":"Rule-based filtering of change events\u00b6","text":"<p>This notebook demonstrates a workflow for loading, filtering, and visualizing change events data.</p>"},{"location":"filtering_of_change_events_rule_based.html#workflow","title":"Workflow\u00b6","text":"<ol> <li><p>Setup and Configuration:</p> <ul> <li>Import necessary modules and set the working directory to ensure paths are relative to the notebook's location.</li> <li>Define input and output paths, along with a rule-based filtering configuration.</li> </ul> </li> <li><p>Data Loading and Filtering:</p> <ul> <li>Load unlabelled change events from a JSON file.</li> <li>Apply a rule-based filter to remove events that do not meet the specified criteria.</li> <li>Save the filtered events to a new JSON file.</li> </ul> </li> <li><p>Visualization:</p> <ul> <li>Compare the unfiltered and filtered datasets by plotting key features such as <code>change_mean</code> and <code>hull_volume</code>.</li> </ul> </li> </ol>"},{"location":"filtering_of_change_events_rule_based.html#outputs","title":"Outputs\u00b6","text":"<ul> <li>Filtered Events File: <code>../test_data/out/change_events_filtered_rule_based.json</code></li> <li>Plots: Visualizations comparing unfiltered and filtered datasets.</li> </ul> <p>This notebook provides a structured approach to preprocessing and analyzing change events data, making it easier to inspect and interpret the results.</p>"},{"location":"filtering_of_change_events_rule_based.html#imports-working-directory","title":"Imports &amp; working directory\u00b6","text":"<p>In order to ensure all imports are available and that paths are relative to this script\u2019s location, we first import modules and set the working directory.</p>"},{"location":"filtering_of_change_events_rule_based.html#define-paths-filtering-rule","title":"Define paths &amp; filtering rule\u00b6","text":"<p>To keep configuration centralized, we declare our input/output paths and the rule we\u2019ll use to filter events. </p> <p>filter_rule = { \"&lt;feature_name&gt;\": {\"min\": &lt;lower_bound&gt;, \"max\": &lt;upper_bound&gt;}, \"&lt;another_feature&gt;\": {\"max\": &lt;upper_bound_only&gt;} }</p>"},{"location":"filtering_of_change_events_rule_based.html#load-filter-save-events","title":"Load, filter &amp; save events\u00b6","text":"<p>In order to apply our rule-based filter, we load all events into a collection, filter by filter_rule, then save the remaining events.</p>"},{"location":"filtering_of_change_events_rule_based.html#visualize-unfiltered-and-filtered-clusters","title":"Visualize unfiltered and filtered clusters\u00b6","text":"<p>To inspect what was removed versus what remains, we re-generate the DataFrame on the filtered collection and plot both sets.</p>"},{"location":"filtering_of_change_events_rule_based.html#project-changes-into-gis-format","title":"Project changes into GIS format\u00b6","text":"<p>Finally, we wrap up by projecting our labelled events into GeoJSON using ProjectChange.</p>"},{"location":"filtering_of_change_events_rule_based.html#projecting-and-visualizing-unfiltered-data","title":"Projecting and visualizing unfiltered data\u00b6","text":""},{"location":"filtering_of_change_events_rule_based.html#projecting-and-visualizing-filtered-data","title":"Projecting and visualizing filtered data\u00b6","text":""},{"location":"main.html","title":"Main AImon5.0 monitoring pipeline","text":"In\u00a0[1]: Copied! <pre># Imports\nimport os\nfrom aimon import run_pipeline\nfrom aimon import utilities\n# Set current directory to the location of the notebook (works even if __file__ is not defined)\ntry:\n    current_dir = os.path.dirname(os.path.abspath(__file__))\nexcept NameError:\n    current_dir = os.getcwd()\n\ncurrent_dir = os.path.dirname(current_dir)\nos.chdir(current_dir)\n</pre> # Imports import os from aimon import run_pipeline from aimon import utilities # Set current directory to the location of the notebook (works even if __file__ is not defined) try:     current_dir = os.path.dirname(os.path.abspath(__file__)) except NameError:     current_dir = os.getcwd()  current_dir = os.path.dirname(current_dir) os.chdir(current_dir) In\u00a0[2]: Copied! <pre># Define parameters\n# You may replace the test files with your own configuration and point cloud files\nconfig_file = \"./test_data/trier_configuration.json\"\nlaz_file_t0 = \"./test_data/240826_000005.laz\"\nlaz_file_t1 = \"./test_data/240826_010006.laz\"\n\n# Run in standard mode\nrun_pipeline(\n    config_file=config_file,\n    filenames=[laz_file_t0,laz_file_t1]\n)\n</pre> # Define parameters # You may replace the test files with your own configuration and point cloud files config_file = \"./test_data/trier_configuration.json\" laz_file_t0 = \"./test_data/240826_000005.laz\" laz_file_t1 = \"./test_data/240826_010006.laz\"  # Run in standard mode run_pipeline(     config_file=config_file,     filenames=[laz_file_t0,laz_file_t1] ) <pre>Finished                                                                        \n</pre> <pre>\n\n</pre> In\u00a0[\u00a0]: Copied! <pre># Plot the projected change events on the image\nimg_path = \"./test_data/out/Trier_vs6_av0_999/03_Change_visualisation_UHD_Projected_Images/Trier_vs6_av0_999_RangeImage.tif\"\nchange_event_file = \"./test_data/out/Trier_vs6_av0_999/04_Change_visualisation_UHD_Change_Events/Trier_vs6_av0_999_change_events_pixel.geojson\"\n\nutilities.plot_change_events(change_event_file, img_path, 'event_type')\n</pre> # Plot the projected change events on the image img_path = \"./test_data/out/Trier_vs6_av0_999/03_Change_visualisation_UHD_Projected_Images/Trier_vs6_av0_999_RangeImage.tif\" change_event_file = \"./test_data/out/Trier_vs6_av0_999/04_Change_visualisation_UHD_Change_Events/Trier_vs6_av0_999_change_events_pixel.geojson\"  utilities.plot_change_events(change_event_file, img_path, 'event_type')"},{"location":"main.html#main-aimon50-monitoring-pipeline","title":"Main AImon5.0 monitoring pipeline\u00b6","text":"<p>This notebook demonstrates how to run the AImon monitoring pipeline on example point cloud data from Trier, Germany. It covers the detection of changes between two epochs and visualizing detected change events on projected image of the study site. Configuration and data files are provided to generate the visual output to help interpret the results.</p> <p>Input:</p> <ul> <li>Configuration file: <code>./test_data/trier_configuration.json</code></li> <li>Two epochs (point cloud files): <code>./test_data/240826_000005.laz</code>, <code>./test_data/240826_010006.laz</code></li> </ul> <p>Output:</p> <ul> <li>Projected range image: <code>./test_data/out/Trier_vs6_av0_999/03_Change_visualisation_UHD_Projected_Images/Trier_vs6_av0_999_RangeImage.tif</code></li> <li>Projected change events (pixel coordinates): <code>./test_data/out/Trier_vs6_av0_999/04_Change_visualisation_UHD_Change_Events/Trier_vs6_av0_999_change_events_pixel.geojson</code></li> <li>Projected change events (georeferenced): <code>./test_data/out/Trier_vs6_av0_999/04_Change_visualisation_UHD_Change_Events/Trier_vs6_av0_999_change_events_gis.geojson</code></li> </ul>"},{"location":"main.html#importing-functions","title":"Importing functions\u00b6","text":""},{"location":"main.html#running-the-main-pipeline-with-two-epochs","title":"Running the main pipeline with two epochs\u00b6","text":""},{"location":"main.html#visualizing-the-change-events","title":"Visualizing the change events\u00b6","text":""},{"location":"main.html#on-the-image-background","title":"On the image background\u00b6","text":""},{"location":"main.html#in-a-gis-software-and-google-earth","title":"In a GIS software and Google Earth\u00b6","text":"<ul> <li>In a GIS software, drag and drop the created GIS file called <code>Trier_vs6_av0_999_change_events_gis.geojson</code>.</li> <li>In Google Earth, drag and drop the created GIS file called <code>Trier_vs6_av0_999_change_events_gis.kml</code>.</li> </ul>"}]}